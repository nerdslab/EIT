<!doctype html>
<html>

<head>
    <title>EIT: Embedded Interaction Transformer</title>
    <meta charset="utf-8" name="viewport" content="width=device-width, initial-scale=1">
    <link href="css/frame.css" media="screen" rel="stylesheet" type="text/css" />
    <link href="css/controls.css" media="screen" rel="stylesheet" type="text/css" />
    <link href="css/custom.css" media="screen" rel="stylesheet" type="text/css" />
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Open+Sans+Condensed:300,700' rel='stylesheet' type='text/css'>
    <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700" rel="stylesheet">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
    <script src="js/menu.js"></script>
    <style>
        .menu-index {
            color: rgb(255, 255, 255) !important;
            opacity: 1 !important;
            font-weight: 700 !important;
        }
    </style>
</head>

<!--
<style>
    img{
        max-width: 100%;
        max-height: 100%;
        display: block; /* remove extra space below image */
    }
    .box{
        width: 500px;
    }
    .box.large{
        height: auto;
    }
</style>
-->

<body>
<div class="menu-container"></div>
<div class="content-container">
    <div class="content">
        <div class="content-table flex-column">

            <!--Start Intro-->
            <div class="flex-row">
                <div class="flex-item flex-column">
                    <h2 class="add-top-margin">Welcome to EIT! (NeurIPS 2022)</h2>
                    <p class="text add-top-margin">
                        This webpage is still in progress. The information may not be accurate.
                        <br>
                        The paper preprint can be found <a target="https://arxiv.org/pdf/2206.06131.pdf" href="https://arxiv.org/pdf/2206.06131.pdf">here</a>.
                        If you use our code, please cite our paper as below.
                        <br>
                        <br>
                        [<b>cite</b>] Ran Liu, Mehdi Azabou, Max Dabagia, Jingyun Xiao, and Eva L. Dyer. 
                        "Seeing the forest and the tree: Building representations of both individual and collective dynamics with transformers." 
                        Advances in Neural Information Processing Systems 35 (2022).
                    </p>
                    
                    <h2 class="add-top-margin">Abstract</h2>
                    <hr>
                    <p class="text add-top-margin">
                        Complex systems (such as the brain) contain multiple individual elements (e.g. neurons) that interact
                        dynamically to generate their outputs. The process by which these local interactions give rise to
                        large-scale behaviors is important in many domains of science and engineering, from ecology and social networks
                        to microbial interactions and brain dynamics.
                    </p>
                    <p class="text add-top-margin">
                        A natural way to model the activity of a system is to build a collective or <em>population-level view</em>,
                        where we consider individuals (or channels) jointly to determine the dynamics of the population. 
                        However, studying systems from this population-level perspective might cause the model to lose sight of the 
                        contributions of different individuals’ dynamics to the final prediction or inference.
                    </p>

                    <h2 class="add-top-margin">Methods</h2>
                    <hr>
                    <p class="text add-top-margin">
                        EIT (Embedded Interaction Transformer) presents a new framework for modeling time-varying observations 
                        of a system by using dynamic embeddings of individual channels to construct a population-level view.
                    </p>
                </div>
            </div>
            <div class="flex-row">
                <div class="flex-item flex-column">
                    <a class="image center adaptive-image" style="background-image: url('img/overview.png'); width: 100%; max-width: 1200px; min-height: 200px;" href="img/overview_swapVAE.jpg" target="_blank"></a>
                    <p class="text text-center graph-title">
                        The overview image of EIT.
                    </p>
                    <p class="text">
                        <!--<img class="image image-wrap-text max-width-550" src="img/Fig1_overview.png">-->
                        EIT decomposes multi-channel time-series by first learning rich features from individual time-series before 
                        incorporating information and learned interactions across different individuals in the population.
                        One critical benefit of our model is <em>spatial/individual separability</em>: it builds a population-level 
                        representation from embeddings of individual channels, which naturally leads to channel-level permutation invariance. 
                        In domain generalization tasks, this means a trained model can be tested with permuted channels or entirely
                        different number of channels.
                    </p>
                    
                    <h2 class="add-top-margin">Contributions</h2>
                    <hr>
                    <p class="text add-top-margin">
                        Our contributions are as follows:
                        <ul>
                            <li>We proposed a novel framework that considers individual dynamics before collective dynamics, and realized 
                                it with a multi-stage transformer <b>EIT</b>. EIT learns both population representation and individual representation 
                                through decoupling the dynamics of individuals and their interactions in multi-variate time-series. </li>
                            <li>We introduced methods for generalization across datasets of different input size (number of channels) and ordering. 
                                We further proposed to measure the alignments of time-series in different datasets through the Wasserstein divergence. </li>
                            <li>We applied EIT to both many-body systems and neural systems recordings. After demonstrating our model’s robust 
                                decoding performance, we validated its ability to transfer individual dynamics by performing domain generalization 
                                across different populations of neurons and finding neuron alignments. </li>
                        </ul>
                    </p>

                </div>
            </div>
            <!--End Intro-->
            
            

            <!--Start Text Only-->
            <div class="flex-row">
                <div class="flex-item flex-column">
                    <h2 class="add-top-margin">Team</h2>
                    <hr>
                    <ol class="publication">
                        <li>
                            <p class="text-small-margin">
                                Ran Liu (<a target="_blank" href="https://ranliu98.github.io/">web</a>),
                                Mehdi Azabou,
                                Max Dabagia (<a target="_blank" href="https://mdabagia.github.io/">web</a>),
                                Jingyun Xiao, 
                                Eva Dyer (<a target="_blank" href="https://dyerlab.gatech.edu/people/pi-profile/">web</a>).
                            </p>
                        </li>
                    </ol>
                </div>
            </div>
            <!--End Text Only-->

        </div>
    </div>
</div>
</body>

</html>
